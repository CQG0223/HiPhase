Epoch		Train-loss		Val-loss		learningRate
1		3.1295		2.8633		0.00050000
2		2.2172		1.8796		0.00049625
3		1.7990		1.6730		0.00049249
4		1.5714		1.4763		0.00048874
5		1.3254		1.1852		0.00048497
6		1.1959		1.0211		0.00048121
7		1.0464		0.9021		0.00047744
8		0.9481		0.7962		0.00047367
9		0.8580		1.6417		0.00046990
10		0.8080		0.7253		0.00046612
11		0.7495		0.7670		0.00046234
12		0.7050		0.5994		0.00045855
13		0.6277		0.5276		0.00045477
14		0.5814		0.4850		0.00045097
15		0.5691		0.4549		0.00044718
16		0.5275		0.4230		0.00044338
17		0.4742		0.3989		0.00043958
18		0.4502		0.3861		0.00043577
19		0.4276		0.3575		0.00043196
20		0.4102		0.4058		0.00042815
21		0.3640		0.3033		0.00042433
22		0.3394		0.2856		0.00042051
23		0.3148		0.2636		0.00041669
24		0.3120		0.4883		0.00041286
25		0.3305		0.3046		0.00040903
26		0.3432		0.3126		0.00040519
27		0.4279		0.4451		0.00040135
28		0.4524		1.3169		0.00039750
29		0.5042		0.3769		0.00039366
30		0.4130		0.3797		0.00038980
31		0.3643		0.2580		0.00038594
32		0.3046		0.2283		0.00038208
33		0.2618		0.2143		0.00037822
34		0.2420		0.2024		0.00037435
35		0.2331		0.1860		0.00037047
36		0.2207		0.1770		0.00036659
37		0.2111		0.1707		0.00036271
38		0.2047		0.1660		0.00035882
39		0.1906		0.1585		0.00035493
40		0.1871		0.1532		0.00035103
41		0.1842		0.1479		0.00034713
42		0.1730		0.1492		0.00034322
43		0.1688		0.1386		0.00033931
44		0.1677		0.1347		0.00033539
45		0.1642		0.1338		0.00033147
46		0.1619		0.1297		0.00032754
47		0.1532		0.1231		0.00032361
48		0.1501		0.1217		0.00031967
49		0.1465		0.1185		0.00031572
50		0.1399		0.1150		0.00031177
51		0.1386		0.1101		0.00030782
52		0.1382		0.1130		0.00030386
53		0.1341		0.1048		0.00029989
54		0.1274		0.1023		0.00029592
55		0.1227		0.1004		0.00029194
56		0.1228		0.0965		0.00028796
57		0.1196		0.0943		0.00028397
58		0.1221		0.0963		0.00027997
59		0.1193		0.0947		0.00027597
60		0.1166		0.0873		0.00027196
61		0.1139		0.0847		0.00026794
62		0.1073		0.0839		0.00026392
63		0.1094		0.0900		0.00025989
64		0.1068		0.0818		0.00025586
65		0.1054		0.0824		0.00025181
66		0.1018		0.0808		0.00024776
67		0.1101		0.0942		0.00024370
68		0.1073		0.0789		0.00023964
69		0.1030		0.0741		0.00023556
70		0.0952		0.0724		0.00023148
71		0.0939		0.0717		0.00022739
72		0.0875		0.0695		0.00022330
73		0.0878		0.0676		0.00021919
74		0.0873		0.0676		0.00021508
75		0.0869		0.0671		0.00021095
76		0.0861		0.0669		0.00020682
77		0.0826		0.0636		0.00020268
78		0.0799		0.0618		0.00019853
79		0.0799		0.0628		0.00019437
80		0.0818		0.0608		0.00019020
81		0.0797		0.0616		0.00018602
82		0.0772		0.0601		0.00018183
83		0.0754		0.0584		0.00017763
84		0.0741		0.0587		0.00017342
85		0.0746		0.0570		0.00016919
86		0.0730		0.0564		0.00016496
87		0.0697		0.0557		0.00016071
88		0.0711		0.0552		0.00015645
89		0.0715		0.0547		0.00015217
90		0.0791		0.0638		0.00014789
91		0.0839		0.0625		0.00014359
92		0.0769		0.0562		0.00013927
93		0.0704		0.0551		0.00013494
94		0.0735		0.0554		0.00013060
95		0.0709		0.0538		0.00012624
96		0.0716		0.0527		0.00012186
97		0.0679		0.0524		0.00011746
98		0.0666		0.0513		0.00011305
99		0.0652		0.0511		0.00010861
100		0.0661		0.0510		0.00010416
101		0.0651		0.0497		0.00009969
102		0.0642		0.0502		0.00009519
103		0.0627		0.0496		0.00009067
104		0.0632		0.0500		0.00008612
105		0.0627		0.0492		0.00008155
106		0.0617		0.0491		0.00007695
107		0.0624		0.0488		0.00007231
108		0.0621		0.0488		0.00006765
109		0.0615		0.0480		0.00006295
110		0.0627		0.0480		0.00005821
111		0.0605		0.0481		0.00005342
112		0.0592		0.0481		0.00004859
113		0.0606		0.0473		0.00004370
114		0.0612		0.0474		0.00003875
115		0.0591		0.0474		0.00003373
116		0.0597		0.0468		0.00002863
117		0.0610		0.0470		0.00002342
118		0.0607		0.0469		0.00001808
119		0.0588		0.0472		0.00001255
120		0.0591		0.0468		0.00000673